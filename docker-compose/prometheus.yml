# my global config
global:
    scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
    evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
    # scrape_timeout is set to the global default (10s).

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
# - "first_rules.yml"
# - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
    # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
    - job_name: 'prometheus'
#      metrics_path: '/actuator/prometheus'
        # metrics_path defaults to '/metrics'
        # scheme defaults to 'http'.
      static_configs:
          - targets: ['0.0.0.0:9090']

    - job_name: 'auth-service'
      metrics_path: '/actuator/prometheus'
      scrape_interval: 15s
      static_configs:
          - targets: ['auth-service:9999']

    - job_name: 'todo-service'
      metrics_path: '/metrics'
      scrape_interval: 15s
      static_configs:
          - targets: ['todo-service:8083']

    - job_name: 'person-service'
      metrics_path: '/actuator/prometheus'
      scrape_interval: 15s
      static_configs:
        - targets: ['person-service:8082']

    - job_name: 'zuul-server'
      metrics_path: '/actuator/prometheus'
      scrape_interval: 15s
      static_configs:
        - targets: ['zuul-server:8764']
